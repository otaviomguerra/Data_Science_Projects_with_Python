{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Challenge Kaggle.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aqui faço um pequeno código para o desafio do titanic(https://www.kaggle.com/c/titanic).\n",
    "### O desafio consiste em predizer os sobreviventes e não-sobreviventes do acidente levando em consideração algumas informações dos passageiros.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando as bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando os dados de treinamento e separando as variaveis de treinamento: X_train e y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = pd.read_csv(\"train.csv\")\n",
    "dataset_train = dataset_train.drop(['PassengerId', 'Name', 'Cabin', 'Ticket'], axis = 1)\n",
    "X_train = dataset_train.drop(['Survived'], axis = 1)\n",
    "y_train = dataset_train['Survived'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando os dados de Teste e separando as variaveis de teste: X_test e y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = pd.read_csv(\"test.csv\")\n",
    "dataset_test = dataset_test.drop(['PassengerId', 'Name', 'Cabin', 'Ticket'], axis = 1)\n",
    "X_test = dataset_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Em seguida, criamos 2 novas variaveis a partir das existentes: Tamanho da Família(FamilySize) e uma variavel binária para indicar se o passageiro estava ou não sem familiares na viagem(IsAlone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['FamilySize'] = X_train['SibSp'] + X_train['Parch'] + 1\n",
    "X_train['IsAlone'] = 1\n",
    "X_train['IsAlone'].loc[X_train['FamilySize'] > 1] = 0\n",
    "\n",
    "X_test['FamilySize'] = X_test['SibSp'] + X_test['Parch'] + 1\n",
    "X_test['IsAlone'] = 1\n",
    "X_test['IsAlone'].loc[X_test['FamilySize'] > 1] = 0       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agora temos que lidar com os dados faltantes no dataset, depois de alguns testes escolhi preenche-los com mediana e moda da coluna correspondente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['Age'].fillna(X_train['Age'].median(), inplace = True)\n",
    "X_train['Embarked'].fillna(X_train['Embarked'].mode()[0], inplace = True)\n",
    "X_train['Fare'].fillna(X_train['Fare'].median(), inplace = True)\n",
    "\n",
    "X_test['Age'].fillna(X_test['Age'].median(), inplace = True)\n",
    "X_test['Embarked'].fillna(X_test['Embarked'].mode()[0], inplace = True)\n",
    "X_test['Fare'].fillna(X_test['Fare'].median(), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agora precisamos lidar com as variáveis categoricas do dataset, já que a maioria dos algoritmos só lidam com números"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = LabelEncoder()\n",
    "X_train['Sex'] = label.fit_transform(X_train['Sex'])\n",
    "X_train['Embarked'] = label.fit_transform(X_train['Embarked'])\n",
    "onehotencoder = OneHotEncoder(categorical_features=[6])\n",
    "X_train = onehotencoder.fit_transform(X_train).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = LabelEncoder()\n",
    "X_test['Sex'] = label.fit_transform(X_test['Sex'])\n",
    "X_test['Embarked'] = label.fit_transform(X_test['Embarked'])\n",
    "onehotencoder = OneHotEncoder(categorical_features=[6])\n",
    "X_test = onehotencoder.fit_transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precisamos agora normalizar os dados para acelerar o processo de treinamento e entre outras vantagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos agora treinar o classificador, o melhor classificador testado anteriormente foi o XGBOOST algoritmo baseado na técnica de Boosting como o próprio nome já indica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=120,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = XGBClassifier(n_estimators=120)\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Após o treinamento, guardamos o resultado de saída do modelo para o nosso conjunto de teste na variável y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para avaliar o modelo, utilizo k-fold cross validation escolhendo k=10.Essa técnica é uma das técnicas mais utilizadas por cientistas de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média de acurácia do algoritmo: 0.827237 Desvio Padrão: 0.034067\n"
     ]
    }
   ],
   "source": [
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "mean = accuracies.mean()\n",
    "std = accuracies.std()\n",
    "print(\"Média de acurácia do algoritmo: %f Desvio Padrão: %f\" % (mean, std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Essa taxa de acerto é satisfatória, portanto, enviaremos o csv das predições para a submissão da competição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_csv('test.csv')\n",
    "PassengerId = temp['PassengerId']\n",
    "Submission = pd.DataFrame({ 'PassengerId': PassengerId,\n",
    "                            'Survived': y_pred })\n",
    "Submission.to_csv(\"Submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
